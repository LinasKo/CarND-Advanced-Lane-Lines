{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Composition\n",
    "In this notebook I shall compose all the methods that I worked on so far and develop the final solution. A LOT of tinkering and moving around will be done, and some new features might be added, but I'll likely skip long sections for intermediate steps and directly include it in the document. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T18:59:11.140851Z",
     "start_time": "2018-09-11T18:59:11.132830Z"
    },
    "tags": [
     "#path"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for root folder of the project...\n",
      "Root folder found. Now working in directory 'D:\\Linas\\projects\\CarND-Advanced-Lane-Lines'\n"
     ]
    }
   ],
   "source": [
    "# Set the right working folder to root folder of the project\n",
    "import os\n",
    "\n",
    "print(\"Looking for root folder of the project...\")\n",
    "for folder_depth in range(100): \n",
    "    if os.path.exists(\".git\"):\n",
    "        root_folder = os.getcwd()\n",
    "        print(\"Root folder found. Now working in directory '%s'\" % os.getcwd())\n",
    "        break\n",
    "    else:\n",
    "        print(\"Going up from '%s'\" % os.getcwd())\n",
    "        os.chdir(\"..\")\n",
    "else:\n",
    "    raise Exception(\"Root folder of the project not found. Terminating.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T19:04:35.114104Z",
     "start_time": "2018-09-11T19:04:35.103074Z"
    },
    "tags": [
     "#init",
     "=>path"
    ]
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from moviepy.editor import clips_array\n",
    "from moviepy.editor import ipython_display\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from math import ceil\n",
    "\n",
    "\n",
    "class Plotter:\n",
    "    def __init__(self, columns, figsize=(20, 40)):\n",
    "        plt.figure(figsize=figsize)\n",
    "        \n",
    "        self.columns = columns\n",
    "        self.images = []\n",
    "        self.extra_plots = []\n",
    "        \n",
    "    def add_img(self, img, title):\n",
    "        assert len(img.shape) == 2 or img.shape[2] == 3\n",
    "        \n",
    "        cmap = None\n",
    "        if len(img.shape) == 2:\n",
    "            cmap = \"gray\"\n",
    "\n",
    "        self.images.append((img, title, cmap))\n",
    "        self.extra_plots.append([])\n",
    "        \n",
    "    def add_extra_to_last_img(self, xs, ys, plot_type):\n",
    "        assert plot_type in [\"line\"]\n",
    "        self.extra_plots[-1].append((xs, ys, plot_type))\n",
    "            \n",
    "    def plot(self):\n",
    "        j = 1  # Current column\n",
    "        i = 0\n",
    "        rows = ceil(len(self.images) // self.columns)\n",
    "        for img_index, (img, title, cmap) in enumerate(self.images):\n",
    "            # Draw iamge\n",
    "            ax = plt.subplot((rows / self.columns + 1) * self.columns, self.columns, i * self.columns + j)\n",
    "            ax.set_title(title)\n",
    "            \n",
    "            # Draw Extras\n",
    "            for xs, ys, plot_type in self.extra_plots[img_index]:\n",
    "                if plot_type == \"line\":\n",
    "                    plt.plot(xs, ys, color='yellow')\n",
    "            \n",
    "            # Show\n",
    "            plt.imshow(img, cmap=\"gray\")\n",
    "            \n",
    "            if j % self.columns == 0:\n",
    "                j = 0\n",
    "                i += 1\n",
    "            j += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T19:04:35.155246Z",
     "start_time": "2018-09-11T19:04:35.118123Z"
    },
    "tags": [
     "#prev-work",
     "=>path",
     "=>init"
    ]
   },
   "outputs": [],
   "source": [
    "YM_PER_PX = 30 / 720\n",
    "XM_PER_PX = 3.7 / 700\n",
    "\n",
    "\n",
    "def apply_precomputed_undistortion(img, mtx_filename, dist_filename):\n",
    "    mtx = np.load(mtx_filename)\n",
    "    dist = np.load(dist_filename)\n",
    "    undist_img = cv2.undistort(img, mtx, dist)\n",
    "    return undist_img\n",
    "\n",
    "\n",
    "def threshold_image(img):\n",
    "    # Saturation-based thresholding\n",
    "    hls_img = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    s_channel = hls_img[:, :, 2]\n",
    "    \n",
    "    s_thresh_value = 150\n",
    "    s_thresh = np.zeros_like(s_channel)\n",
    "    s_thresh[s_channel > s_thresh_value] = 1\n",
    "    \n",
    "    # Edge Detection\n",
    "    red = img[:, :, 0]\n",
    "    sobel_kernel = 25\n",
    "    assert sobel_kernel >= 3 and sobel_kernel % 2 == 1\n",
    "    sobel_x = cv2.Sobel(red, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobel_y = cv2.Sobel(red, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    \n",
    "    sobel_x = np.absolute(sobel_x)\n",
    "    sobel_y = np.absolute(sobel_y)\n",
    "\n",
    "    # Magnitude\n",
    "    magnitude = (sobel_x**2 + sobel_y**2)**.5\n",
    "    mag_norm = np.uint8(255 * magnitude / np.max(magnitude))\n",
    "    mag_thresh_value = 30\n",
    "    mag_thresh = np.zeros_like(mag_norm, dtype=np.uint8)\n",
    "    mag_thresh[mag_norm > mag_thresh_value] = 1\n",
    "    \n",
    "    # Direction\n",
    "    atan = np.arctan2(sobel_y, sobel_x)\n",
    "    atan_thresh_min = 0.8\n",
    "    atan_thresh_max = 1.2\n",
    "    dir_thresh = np.zeros_like(atan, dtype=np.uint8)\n",
    "    dir_thresh[(atan > atan_thresh_min) & (atan <= atan_thresh_max)] = 1\n",
    "    \n",
    "    # Combinations\n",
    "    mag_and_dir = cv2.bitwise_and(mag_thresh, dir_thresh)    \n",
    "    grad_or_color = cv2.bitwise_or(mag_and_dir, s_thresh)\n",
    "    \n",
    "    return grad_or_color\n",
    "\n",
    "\n",
    "def warp_perspective(img, x_offset=200, y_offset=100, new_image_shape=(1000, 1000), flags=cv2.INTER_LINEAR):    \n",
    "    # Detect Lines\n",
    "    # Luckily, the camera resolution is 1280 x 720 in all iamges / videos we're given. This means I can hardode the values.\n",
    "    top_left  = [578,  463]\n",
    "    top_right = [706,  463]\n",
    "    bot_right = [1043, 677]\n",
    "    bot_left  = [267,  677]\n",
    "    src_corners = np.float32([top_left, top_right, bot_right, bot_left])\n",
    "    \n",
    "    line_img = np.zeros(new_image_shape, dtype=np.uint8)\n",
    "    \n",
    "    new_top_left  = [x_offset, y_offset]\n",
    "    new_top_right = [line_img.shape[1] - x_offset, y_offset]\n",
    "    new_bot_right = [line_img.shape[1] - x_offset, line_img.shape[0] - y_offset]\n",
    "    new_bot_left  = [x_offset, line_img.shape[0] - y_offset]\n",
    "    dst_corners = np.float32([new_top_left, new_top_right, new_bot_right, new_bot_left])\n",
    "    \n",
    "    transform_matrix = cv2.getPerspectiveTransform(src_corners, dst_corners)\n",
    "    inv_transform_matrix = cv2.getPerspectiveTransform(dst_corners, src_corners)\n",
    "    warped = cv2.warpPerspective(img, transform_matrix, line_img.shape[::-1], flags=flags)\n",
    "\n",
    "    return warped, transform_matrix, inv_transform_matrix\n",
    "\n",
    "\n",
    "def retrieve_polylines(warped, draw_windows=True):    \n",
    "    \"\"\"\n",
    "    Takes in the warped thresholds to find polylines on the road\n",
    "    \"\"\"\n",
    "    \n",
    "    # find histogram of half-height\n",
    "    warped_y_midpoint = warped.shape[0] // 2\n",
    "    histogram = np.sum(warped[warped_y_midpoint:, :], axis=0)\n",
    "    out_img = np.dstack((warped, warped, warped))\n",
    "    \n",
    "    # find base points on both sides - max values\n",
    "    hist_x_midpoint = np.int(histogram.shape[0] // 2)\n",
    "    left_x_base = np.argmax(histogram[:hist_x_midpoint])\n",
    "    right_x_base = np.argmax(histogram[hist_x_midpoint:]) + hist_x_midpoint\n",
    "\n",
    "    # Hyperparameters\n",
    "    win_min_pix = 50  # minimum number of pixels found to recenter window\n",
    "    win_num = 9  # the number of sliding windows\n",
    "    win_half_width = 200 // 2\n",
    "    win_height = np.int(warped.shape[0] // win_num)\n",
    "    \n",
    "    # Nonzero pixel indices\n",
    "    nonzero = warped.nonzero()\n",
    "    nonzero_y = np.array(nonzero[0])\n",
    "    nonzero_x = np.array(nonzero[1])\n",
    "    \n",
    "    # Init current midpoint variables and index lists\n",
    "    left_x_current = left_x_base\n",
    "    right_x_current = right_x_base\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "    \n",
    "    for win_index in range(win_num):\n",
    "        # Iterate over windows from the bottom, setting boundaries\n",
    "        win_y_low = warped.shape[0] - (win_index + 1) * win_height\n",
    "        win_y_high = warped.shape[0] - win_index * win_height\n",
    "        win_x_left_low   = left_x_current - win_half_width\n",
    "        win_x_left_high  = left_x_current  + win_half_width\n",
    "        win_x_right_low  = right_x_current - win_half_width\n",
    "        win_x_right_high = right_x_current + win_half_width\n",
    "        \n",
    "        # Draw the windows on the visualization image\n",
    "        if draw_windows:\n",
    "            cv2.rectangle(out_img, (win_x_left_low,  win_y_low), (win_x_left_high,  win_y_high), color=(0, 255, 0), thickness=3)\n",
    "            cv2.rectangle(out_img, (win_x_right_low, win_y_low), (win_x_right_high, win_y_high), color=(0, 255, 0), thickness=3)\n",
    "        \n",
    "        # Conjoin binary index arrays, retrieve y coords of nonzero pixels in each window\n",
    "        good_left_inds = (\n",
    "            (nonzero_x >= win_x_left_low) &\n",
    "            (nonzero_x < win_x_left_high) &\n",
    "            (nonzero_y >= win_y_low) &\n",
    "            (nonzero_y < win_y_high)\n",
    "        ).nonzero()[0]\n",
    "        good_right_inds = (\n",
    "            (nonzero_x >= win_x_right_low) &\n",
    "            (nonzero_x < win_x_right_high) &\n",
    "            (nonzero_y >= win_y_low) &\n",
    "            (nonzero_y < win_y_high)\n",
    "        ).nonzero()[0]\n",
    "        \n",
    "        # Append whole array to a global list\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        \n",
    "        # If enough pixels, shift mean x coordinate of the \n",
    "        if len(good_left_inds) > win_min_pix:\n",
    "            nonzero_x_in_win = nonzero_x[good_left_inds]\n",
    "            left_x_current = np.int(np.mean(nonzero_x_in_win))\n",
    "        if len(good_right_inds) > win_min_pix:\n",
    "            nonzero_x_in_win = nonzero_x[good_right_inds]\n",
    "            right_x_current = np.int(np.mean(nonzero_x_in_win))\n",
    "\n",
    "    # Flatten global list to get all y indices of line pixels for each side\n",
    "    try:\n",
    "        left_lane_inds = np.concatenate(left_lane_inds)\n",
    "        right_lane_inds = np.concatenate(right_lane_inds)\n",
    "    except ValueError as e:\n",
    "        raise e\n",
    "\n",
    "    # Get all (i,j) indices of nonzero pixels within windows, for each side \n",
    "    left_x = nonzero_x[left_lane_inds]\n",
    "    left_y = nonzero_y[left_lane_inds] \n",
    "    right_x = nonzero_x[right_lane_inds]\n",
    "    right_y = nonzero_y[right_lane_inds]\n",
    "    \n",
    "    ## Visualization ##\n",
    "    # Colors in the left and right lane regions\n",
    "    out_img[left_y, left_x] = [255, 0, 0]\n",
    "    out_img[right_y, right_x] = [0, 0, 255]\n",
    "    \n",
    "    # Polyfit using all the points\n",
    "    left_fit = np.polyfit(left_y, left_x, 2)\n",
    "    right_fit = np.polyfit(right_y, right_x, 2)\n",
    "    \n",
    "    # Get real-scaled polylines for curvature calculation\n",
    "    scaled_left_fit = np.polyfit(left_y * YM_PER_PX, left_x * XM_PER_PX, 2)\n",
    "    scaled_right_fit = np.polyfit(right_y * YM_PER_PX, right_x * XM_PER_PX, 2)\n",
    "\n",
    "    return out_img, left_fit, right_fit, (scaled_left_fit, scaled_right_fit)\n",
    "\n",
    "\n",
    "def retrieve_polylines_from_older(warped, left_fit, right_fit, draw_windows=True):\n",
    "    \"\"\"\n",
    "    The same polyfit function, but this time it uses the window around previous polynomial lines to search for pixels.\n",
    "    \"\"\"\n",
    "    # Hyperparameters\n",
    "    win_half_width = 200 // 2\n",
    "\n",
    "    # Nonzero pixel indices\n",
    "    nonzero = warped.nonzero()\n",
    "    nonzero_y = np.array(nonzero[0])\n",
    "    nonzero_x = np.array(nonzero[1])\n",
    "    \n",
    "    # Instead of rectangular windows, find binary arrays with nonzero pixels around given polyfit lines\n",
    "    left_fit_x = left_fit[0] * nonzero_y**2 + left_fit[1] * nonzero_y + left_fit[2]\n",
    "    left_lane_inds = (\n",
    "        (nonzero_x > (left_fit_x - win_half_width)) &\n",
    "        (nonzero_x < (left_fit_x + win_half_width))\n",
    "    )\n",
    "    right_fit_x = right_fit[0] * (nonzero_y**2) + right_fit[1] * nonzero_y + right_fit[2]\n",
    "    right_lane_inds = (\n",
    "        (nonzero_x > (right_fit_x - win_half_width)) &\n",
    "        (nonzero_x < (right_fit_x + win_half_width))\n",
    "    )\n",
    "\n",
    "    # Get all (i,j) indices of nonzero pixels within line-based windows, for each side \n",
    "    left_x = nonzero_x[left_lane_inds]\n",
    "    left_y = nonzero_y[left_lane_inds]\n",
    "    right_x = nonzero_x[right_lane_inds]\n",
    "    right_y = nonzero_y[right_lane_inds]\n",
    "\n",
    "    # Polyfit using all the points\n",
    "    left_fit = np.polyfit(left_y, left_x, 2)\n",
    "    right_fit = np.polyfit(right_y, right_x, 2)\n",
    "    \n",
    "    # Generate list [0, 1, ..., warped.shape[0] - 1]  (along y coordinates)\n",
    "    plot_y = np.linspace(0, warped.shape[0] - 1, warped.shape[0])\n",
    "    \n",
    "    # Generate new left and right fit x coordinates\n",
    "    left_fit_x  = left_fit[0]  * plot_y**2 + left_fit[1]  * plot_y + left_fit[2]\n",
    "    right_fit_x = right_fit[0] * plot_y**2 + right_fit[1] * plot_y + right_fit[2]\n",
    "    \n",
    "    # Prepare output and line image\n",
    "    out_img = np.dstack((warped, warped, warped)) * 255\n",
    "    line_win_img = np.zeros_like(out_img)\n",
    "\n",
    "    # Color all pixels in line-based windows red and blue\n",
    "    out_img[nonzero_y[left_lane_inds],  nonzero_x[left_lane_inds]]  = [255, 0, 0]\n",
    "    out_img[nonzero_y[right_lane_inds], nonzero_x[right_lane_inds]] = [0, 0, 255]\n",
    "\n",
    "    # 2 layers [column vector of left_fit_x ± win_width, column of [0,1,...,height]]\n",
    "    left_line_window_1 = np.array([\n",
    "        np.vstack([left_fit_x - win_half_width, plot_y]).T\n",
    "    ])    \n",
    "    left_line_window_2 = np.array([\n",
    "        np.flipud(np.vstack([left_fit_x + win_half_width, plot_y]).T)\n",
    "    ])\n",
    "    left_line_pts = np.hstack((left_line_window_1, left_line_window_2))\n",
    "    \n",
    "    # 2 layers [column vector of right_fit_x ± win_width, column of [0,1,...,height]]\n",
    "    right_line_window_1 = np.array([\n",
    "        np.vstack([right_fit_x - win_half_width, plot_y]).T\n",
    "    ])\n",
    "    right_line_window_2 = np.array([\n",
    "        np.flipud(np.vstack([right_fit_x + win_half_width, plot_y]).T)\n",
    "    ])\n",
    "    right_line_pts = np.hstack((right_line_window_1, right_line_window_2))\n",
    "\n",
    "    if draw_windows:\n",
    "        # Fill polies within windows\n",
    "        cv2.fillPoly(line_win_img, np.int_([left_line_pts]), (0, 150, 0))\n",
    "        cv2.fillPoly(line_win_img, np.int_([right_line_pts]), (0, 150, 0))\n",
    "        result = cv2.addWeighted(out_img, 1, line_win_img, 0.3, 0)\n",
    "    else:\n",
    "        result = out_img\n",
    "    \n",
    "    return result, left_fit, right_fit, None\n",
    "\n",
    "def generate_polyline_plots(warped_shape, left_fit, right_fit):\n",
    "    # Generate x and y values for plotting\n",
    "    plot_y = np.linspace(0, warped_shape[0] - 1, warped_shape[0])\n",
    "\n",
    "    left_fit_x = left_fit[0] * plot_y**2 + left_fit[1] * plot_y + left_fit[2]\n",
    "    right_fit_x = right_fit[0] * plot_y**2 + right_fit[1] * plot_y + right_fit[2]\n",
    "\n",
    "    # # Now call:\n",
    "    # plotter.add_img(out_img, \"warped image\")\n",
    "    # plotter.add_extra_to_last_img(left_fit_x,  plot_y, \"line\")\n",
    "    # plotter.add_extra_to_last_img(right_fit_x, plot_y, \"line\")\n",
    "    \n",
    "    return left_fit_x, right_fit_x, plot_y\n",
    "    \n",
    "def fit_polynomial(x, coefficients):\n",
    "    res = 0\n",
    "    for power, coeff in enumerate(coefficients[::-1]):\n",
    "        res += coeff * x**power\n",
    "    return res\n",
    "\n",
    "def get_lane_area(warped_line_img, inv_transformation_matrix, original_img_shape, left_fit, right_fit):\n",
    "    # Area between two polylines\n",
    "    all_pts = np.zeros(warped_line_img.shape[:2], dtype=np.uint8)\n",
    "    for y in range(warped_line_img.shape[0]):\n",
    "        poly_left = int(fit_polynomial(y, left_fit))\n",
    "        poly_right = int(fit_polynomial(y, right_fit))\n",
    "        all_pts[y, poly_left:poly_right] = 1\n",
    "    \n",
    "    polyfilled = warped_line_img.copy()\n",
    "    polyfilled[all_pts == 1] = np.array([0, 255, 0])\n",
    "    \n",
    "    # Dewarp\n",
    "    dewarped = cv2.warpPerspective(polyfilled, inv_transformation_matrix, original_img_shape[1::-1], flags=cv2.INTER_LINEAR)\n",
    "    \n",
    "    return dewarped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T19:04:35.168249Z",
     "start_time": "2018-09-11T19:04:35.158223Z"
    },
    "tags": [
     "#polylines-many",
     "=>path",
     "=>init",
     "=>prev-work"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "def retrieve_polylines_from_several_images(warped_images, draw_windows=True):\n",
    "    \"\"\"\n",
    "    Takes in the warped thresholds to find polylines on the road\n",
    "    \"\"\"\n",
    "    fused_img = np.zeros(warped_images.shape[:2], dtype=np.uint8)\n",
    "    for img_index in range(warped_images.shape[2]):\n",
    "        fused_img = cv2.bitwise_or(fused_img, warped_images[:, :, img_index])\n",
    "    \n",
    "    # find histogram of half-height\n",
    "    warped_y_midpoint = warped_images.shape[0] // 2\n",
    "    histogram = np.sum(warped_images[warped_y_midpoint:, :, :], axis=0)\n",
    "    out_img = np.dstack((fused_img, fused_img, fused_img))\n",
    "     \n",
    "    # find base points on both sides - max values\n",
    "    hist_x_midpoint = np.int(histogram.shape[0] // 2)\n",
    "    left_x_base = np.argmax(histogram[:hist_x_midpoint])\n",
    "    right_x_base = np.argmax(histogram[hist_x_midpoint:]) + hist_x_midpoint\n",
    "\n",
    "    # Hyperparameters\n",
    "    win_min_pix = 50  # minimum number of pixels found to recenter window\n",
    "    win_num = 9  # the number of sliding windows\n",
    "    win_half_width = 200 // 2\n",
    "    win_height = np.int(warped_images.shape[0] // win_num)\n",
    "    \n",
    "    # TODO: finish this   \n",
    " \n",
    "#     # Nonzero pixel indices\n",
    "#     nonzero_x_list = []\n",
    "#     nonzero_y_list = []\n",
    "#     for img_index in range(warped_images.shape[2]):\n",
    "#         nonzero = warped_images[:, :, img_index].nonzero()\n",
    "#         print(\"sub: \", np.array(nonzero[0]).shape)\n",
    "#         nonzero_y_list.append(np.array(nonzero[0]))\n",
    "#         nonzero_x_list.append(np.array(nonzero[1]))\n",
    "#     nonzero_y = np.concatenate(nonzero_y_list)\n",
    "#     nonzero_x = np.concatenate(nonzero_x_list)\n",
    "    \n",
    "#     print(nonzero_y.shape)\n",
    "#     print(nonzero_x.shape)\n",
    "    \n",
    "#     # Init current midpoint variables and index lists\n",
    "#     left_x_current = left_x_base\n",
    "#     right_x_current = right_x_base\n",
    "#     left_lane_inds = []\n",
    "#     right_lane_inds = []\n",
    "    \n",
    "#     for win_index in range(win_num):\n",
    "#         # Iterate over windows from the bottom, setting boundaries\n",
    "#         win_y_low = warped.shape[0] - (win_index + 1) * win_height\n",
    "#         win_y_high = warped.shape[0] - win_index * win_height\n",
    "#         win_x_left_low   = left_x_current - win_half_width\n",
    "#         win_x_left_high  = left_x_current  + win_half_width\n",
    "#         win_x_right_low  = right_x_current - win_half_width\n",
    "#         win_x_right_high = right_x_current + win_half_width\n",
    "        \n",
    "#         # Draw the windows on the visualization image\n",
    "#         if draw_windows:\n",
    "#             cv2.rectangle(out_img, (win_x_left_low,  win_y_low), (win_x_left_high,  win_y_high), color=(0, 255, 0), thickness=3)\n",
    "#             cv2.rectangle(out_img, (win_x_right_low, win_y_low), (win_x_right_high, win_y_high), color=(0, 255, 0), thickness=3)\n",
    "        \n",
    "#         # Conjoin binary index arrays, retrieve y coords of nonzero pixels in each window\n",
    "#         good_left_inds = (\n",
    "#             (nonzero_x >= win_x_left_low) &\n",
    "#             (nonzero_x < win_x_left_high) &\n",
    "#             (nonzero_y >= win_y_low) &\n",
    "#             (nonzero_y < win_y_high)\n",
    "#         ).nonzero()[0]\n",
    "#         good_right_inds = (\n",
    "#             (nonzero_x >= win_x_right_low) &\n",
    "#             (nonzero_x < win_x_right_high) &\n",
    "#             (nonzero_y >= win_y_low) &\n",
    "#             (nonzero_y < win_y_high)\n",
    "#         ).nonzero()[0]\n",
    "        \n",
    "#         # Append whole array to a global list\n",
    "#         left_lane_inds.append(good_left_inds)\n",
    "#         right_lane_inds.append(good_right_inds)\n",
    "        \n",
    "#         # If enough pixels, shift mean x coordinate of the \n",
    "#         if len(good_left_inds) > win_min_pix:\n",
    "#             nonzero_x_in_win = nonzero_x[good_left_inds]\n",
    "#             left_x_current = np.int(np.mean(nonzero_x_in_win))\n",
    "#         if len(good_right_inds) > win_min_pix:\n",
    "#             nonzero_x_in_win = nonzero_x[good_right_inds]\n",
    "#             right_x_current = np.int(np.mean(nonzero_x_in_win))\n",
    "\n",
    "#     # Flatten global list to get all y indices of line pixels for each side\n",
    "#     try:\n",
    "#         left_lane_inds = np.concatenate(left_lane_inds)\n",
    "#         right_lane_inds = np.concatenate(right_lane_inds)\n",
    "#     except ValueError as e:\n",
    "#         raise e\n",
    "\n",
    "#     # Get all (i,j) indices of nonzero pixels within windows, for each side \n",
    "#     left_x = nonzero_x[left_lane_inds]\n",
    "#     left_y = nonzero_y[left_lane_inds] \n",
    "#     right_x = nonzero_x[right_lane_inds]\n",
    "#     right_y = nonzero_y[right_lane_inds]\n",
    "    \n",
    "#     ## Visualization ##\n",
    "#     # Colors in the left and right lane regions\n",
    "#     out_img[left_y, left_x] = [255, 0, 0]\n",
    "#     out_img[right_y, right_x] = [0, 0, 255]\n",
    "    \n",
    "#     # Polyfit using all the points\n",
    "#     left_fit = np.polyfit(left_y, left_x, 2)\n",
    "#     right_fit = np.polyfit(right_y, right_x, 2)\n",
    "\n",
    "    left_fit = [1, 1, 1]\n",
    "    right_fit = [1, 2, 3]\n",
    "\n",
    "    return out_img, left_fit, right_fit, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T18:59:11.156406Z",
     "start_time": "2018-09-11T18:59:11.143374Z"
    },
    "tags": [
     "#heuristics",
     "=>path",
     "=>init",
     "=>prev-work",
     "=>polylines-many"
    ]
   },
   "outputs": [],
   "source": [
    "def threshold_yellow_lines(hls_img):\n",
    "    \"\"\"\n",
    "    This function attempts to detect only the yellow lines.\n",
    "    \n",
    "    Why try to make a general function for detecting all lane lines, when we can easily distinguish two types - yellow and white?\n",
    "    (actually, there's a third type, when road side is used as a line, with no explicit line marking)\n",
    "    \n",
    "    I have consulted https://driversed.com/driving-information/signs-signals-and-markings/markings-colors-patterns-meaning.aspx,\n",
    "    verifying that only two color types exist.\n",
    "    \"\"\"\n",
    "    # Convert to hls\n",
    "    h_channel = hls_img[:, :, 0]\n",
    "    l_channel = hls_img[:, :, 1]\n",
    "    s_channel = hls_img[:, :, 2]\n",
    "    \n",
    "    thresh = np.zeros_like(h_channel)\n",
    "    thresh[\n",
    "        (h_channel >= 11) & (h_channel <= 30) &\n",
    "        (s_channel >= 50) &\n",
    "        (l_channel >= 150)\n",
    "    ] = 255\n",
    "    \n",
    "    return thresh\n",
    "\n",
    "\n",
    "def threshold_strong_sat_light(hls_img):\n",
    "    h_channel = hls_img[:, :, 0]\n",
    "    l_channel = hls_img[:, :, 1]\n",
    "    s_channel = hls_img[:, :, 2]\n",
    "    \n",
    "    thresh = np.zeros_like(h_channel)\n",
    "    thresh[\n",
    "        (s_channel >= 150) &\n",
    "        (l_channel >= 128)\n",
    "    ] = 255\n",
    "\n",
    "    return thresh\n",
    "\n",
    "\n",
    "def apply_sobel(channel, kernel_size):\n",
    "    assert kernel_size >= 3 and kernel_size % 2 == 1\n",
    "    sobel_x = cv2.Sobel(channel, cv2.CV_64F, 1, 0, ksize=kernel_size)\n",
    "    sobel_y = cv2.Sobel(channel, cv2.CV_64F, 0, 1, ksize=kernel_size)\n",
    "    \n",
    "    sobel_x = np.absolute(sobel_x)\n",
    "    sobel_y = np.absolute(sobel_y)\n",
    "    \n",
    "    return sobel_x, sobel_y\n",
    "\n",
    "\n",
    "def threshold_magnitude(sobel_x, sobel_y):\n",
    "    magnitude = (sobel_x**2 + sobel_y**2)**.5\n",
    "    mag_norm = np.uint8(255 * magnitude / np.max(magnitude))\n",
    "    mag_thresh_value = 30\n",
    "    mag_thresh = np.zeros_like(mag_norm, dtype=np.uint8)\n",
    "    mag_thresh[mag_norm > mag_thresh_value] = 255\n",
    "    \n",
    "    return mag_thresh\n",
    "\n",
    "\n",
    "def threshold_direction(sobel_x, sobel_y):\n",
    "    atan = np.arctan2(sobel_y, sobel_x)  # returns results in range [0.0, 1.57079632679]\n",
    "    atan_thresh_max = 1.2\n",
    "    dir_thresh = np.zeros_like(atan, dtype=np.uint8)\n",
    "    dir_thresh[(atan <= atan_thresh_max)] = 255\n",
    "    \n",
    "    return dir_thresh\n",
    "\n",
    "\n",
    "def morph_close(thresh, kernel_size):\n",
    "    assert kernel_size >= 3 and kernel_size % 2 == 1\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size, kernel_size))\n",
    "    closed = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "    return closed\n",
    "    \n",
    "    \n",
    "def get_distorted_hood_mask():\n",
    "    \"\"\"\n",
    "    Returns the original image mask with the hood area masked\n",
    "    \"\"\"\n",
    "    mask_filename = os.path.join(root_folder, \"masks\", \"distorted_hood_mask.png\")\n",
    "#     mask_rgb = mpimg.imread(mask_filename)\n",
    "    mask_bgr = cv2.imread(mask_filename)\n",
    "    \n",
    "    \n",
    "    mask = np.zeros(mask_bgr.shape[:2], dtype=np.uint8)\n",
    "    mask[\n",
    "        (mask_bgr[:, :, 0] == 255) & \n",
    "        (mask_bgr[:, :, 1] == 255) & \n",
    "        (mask_bgr[:, :, 2] == 0)\n",
    "    ] = 255\n",
    "    mask = cv2.bitwise_not(mask)\n",
    "                    \n",
    "    return mask\n",
    "\n",
    "\n",
    "def compute_curvature(max_y, scaled_left_fit, scaled_right_fit):\n",
    "    # Calculation of R_curve (radius of curvature)\n",
    "    left_curverad  = ((1 + (2 * scaled_left_fit[0] * max_y * YM_PER_PX  + scaled_left_fit[1]) ** 2) ** 1.5)  / np.absolute(2 * scaled_left_fit[0])\n",
    "    right_curverad = ((1 + (2 * scaled_right_fit[0] * max_y * YM_PER_PX + scaled_right_fit[1]) ** 2) ** 1.5) / np.absolute(2 * scaled_right_fit[0])\n",
    "    \n",
    "    return left_curverad, right_curverad\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T19:04:35.101071Z",
     "start_time": "2018-09-11T19:04:35.083023Z"
    },
    "tags": [
     "#process",
     "=>prev-work",
     "=>heuristics",
     "=>polylines-many"
    ]
   },
   "outputs": [],
   "source": [
    "def make_color(func):\n",
    "    \"\"\"\n",
    "    Converts the result to a color image if a grayscale is provided\n",
    "    \"\"\"\n",
    "    def wrapper(*args, **kwargs):\n",
    "        img = func(*args, **kwargs)\n",
    "        if len(np.shape(img)) == 2:\n",
    "            return cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "        else:\n",
    "            return img\n",
    "        \n",
    "    return wrapper\n",
    "\n",
    "\n",
    "\n",
    "@make_color\n",
    "def process_img(rgb_img,\n",
    "                left_lines, right_lines, line_history_length,\n",
    "                prev_left_holder, prev_right_holder,\n",
    "                scaled_left_lines, scaled_right_lines):\n",
    "    # Get hood mask to ignore hood area\n",
    "    dist_hood_mask = get_distorted_hood_mask()\n",
    "        \n",
    "    # Undistort Image\n",
    "    mtx_filename  = os.path.join(root_folder, \"params\", \"camera_matrix.npy\")\n",
    "    dist_filename = os.path.join(root_folder, \"params\", \"dist_coeffs.npy\")\n",
    "    undistorted = apply_precomputed_undistortion(rgb_img, mtx_filename, dist_filename)\n",
    "    hood_mask = apply_precomputed_undistortion(dist_hood_mask, mtx_filename, dist_filename)    \n",
    "    hood_mask[hood_mask < 100] = 0     # Undo the effects of linear interpollation\n",
    "    hood_mask[hood_mask >= 100] = 255\n",
    "\n",
    "    # RGB -> HLS\n",
    "    hls_img = cv2.cvtColor(undistorted, cv2.COLOR_RGB2HLS)\n",
    "    h_channel = hls_img[:, :, 0]\n",
    "    l_channel = hls_img[:, :, 1]\n",
    "    s_channel = hls_img[:, :, 2]\n",
    "    \n",
    "    # Find x and y edges\n",
    "    l_sobel_x, l_sobel_y = apply_sobel(l_channel, 25)\n",
    "    s_sobel_x, s_sobel_y = apply_sobel(s_channel, 25)\n",
    "    \n",
    "#     # Threshold by color\n",
    "#     thresh_yellow = threshold_yellow_lines(hls_img)\n",
    "#     thresh_sat_light = threshold_strong_sat_light(hls_img)\n",
    "\n",
    "    # Threshold by edge magnitude\n",
    "    l_thresh_mag = threshold_magnitude(l_sobel_x, l_sobel_y)\n",
    "    s_thresh_mag = threshold_magnitude(s_sobel_x, s_sobel_y)\n",
    "    thresh_mag = cv2.bitwise_or(l_thresh_mag, s_thresh_mag)\n",
    "    \n",
    "    # Threshold by edge direction\n",
    "    l_thresh_dir = threshold_direction(l_sobel_x, l_sobel_y)  # I results are slightly better with just lightness-based threshold than both.\n",
    "    \n",
    "    # Combine edge magnitude and direction\n",
    "    thresh_edges = cv2.bitwise_and(thresh_mag, l_thresh_dir)\n",
    "\n",
    "    # Fill in gaps between edges\n",
    "    closed_edges = morph_close(thresh_edges, 5)\n",
    "    \n",
    "    # Apply hood mask\n",
    "    closed_edges = cv2.bitwise_and(closed_edges, hood_mask)\n",
    "\n",
    "#     thresh_yellow = cv2.bitwise_and(thresh_yellow, hood_mask)\n",
    "#     thresh_sat_light = cv2.bitwise_and(thresh_sat_light, hood_mask)\n",
    "    \n",
    "#     # Fuse all thresholds\n",
    "#     thresh_color = cv2.bitwise_or(thresh_yellow, thresh_sat_light)\n",
    "#     final_thresh = cv2.bitwise_and(closed_edges, thresh_color)\n",
    "    final_thresh = closed_edges\n",
    "    \n",
    "    warped, transformation_matrix, inv_transformation_matrix = warp_perspective(\n",
    "        final_thresh, x_offset=200, y_offset=100, new_image_shape=closed_edges.shape[:2]\n",
    "    )\n",
    "    \n",
    "    # Focus on the road lines by warping perspective\n",
    "#     warped_edges, transformation_matrix, inv_transformation_matrix = warp_perspective(\n",
    "#         closed_edges, x_offset=200, y_offset=100, new_image_shape=closed_edges.shape[:2]\n",
    "#     )\n",
    "#     warped_yellows, _, _ = warp_perspective(\n",
    "#         thresh_yellow, x_offset=200, y_offset=100, new_image_shape=thresh_yellow.shape[:2]\n",
    "#     )\n",
    "#     warped_whites, _, _ = warp_perspective(\n",
    "#         thresh_sat_light, x_offset=200, y_offset=100, new_image_shape=thresh_sat_light.shape[:2]\n",
    "#     )\n",
    "    \n",
    "#     # Fit a polyline\n",
    "    warped_line_img, left_fit, right_fit, scaled_lines = retrieve_polylines(warped, draw_windows=False)\n",
    "    \n",
    "# #     if prev_left_holder[0] is None or prev_right_holder[0] is None:\n",
    "# #         warped_line_img, left_fit, right_fit, _ = retrieve_polylines(warped_edges, draw_windows=False)\n",
    "# #     else:\n",
    "# #         warped_line_img, left_fit, right_fit, _ = retrieve_polylines_from_older(\n",
    "# #             warped_edges, prev_left_holder[0], prev_right_holder[0], draw_windows=False\n",
    "# #         )\n",
    "\n",
    "# #     warped_line_img, left_fit, right_fit, _ = retrieve_polylines_from_several_images(\n",
    "# #         np.dstack([warped_edges, warped_yellows, warped_whites]), draw_windows=False\n",
    "# #     )\n",
    "\n",
    "    # Average the lines\n",
    "    left_lines.append(left_fit)\n",
    "    if len(left_lines) > line_history_length:\n",
    "        del left_lines[0]\n",
    "    avg_left_fit = np.mean(left_lines, axis=0)\n",
    "#     prev_left_holder[0] = avg_left_fit\n",
    "    \n",
    "    right_lines.append(right_fit)\n",
    "    if len(right_lines) > line_history_length:\n",
    "        del right_lines[0]\n",
    "    avg_right_fit = np.mean(right_lines, axis=0)\n",
    "#     prev_right_holder[0] = avg_right_fit\n",
    "    \n",
    "    # Compute curvature\n",
    "    \n",
    "    \n",
    "#     # Draw the area\n",
    "#     dewarped = get_lane_area(warped_line_img, inv_transformation_matrix, rgb_img.shape, avg_left_fit, avg_right_fit)\n",
    "    \n",
    "#     # Overlay\n",
    "#     alpha = 0.2\n",
    "#     combined_img = np.zeros_like(undistorted)\n",
    "#     cv2.addWeighted(dewarped, alpha, undistorted, 1 - alpha, 0, combined_img)\n",
    "    \n",
    "    combined_img = warped_line_img\n",
    "    \n",
    "#     # Average the scaled lines for curvature calculation\n",
    "#     if scaled_lines is not None:\n",
    "#         scaled_left_fit, scaled_right_fit = scaled_lines\n",
    "\n",
    "#         scaled_left_lines.append(scaled_left_fit)\n",
    "#         if len(scaled_left_lines) > line_history_length:\n",
    "#             del scaled_left_lines[0]\n",
    "#         scaled_avg_left_fit = np.mean(scaled_left_lines, axis=0)\n",
    "\n",
    "#         scaled_right_lines.append(scaled_right_fit)\n",
    "#         if len(scaled_right_lines) > line_history_length:\n",
    "#             del scaled_right_lines[0]\n",
    "#         scaled_avg_right_fit = np.mean(scaled_right_lines, axis=0)\n",
    "        \n",
    "#         left_curverad, right_curverad = compute_curvature(677, scaled_avg_left_fit, scaled_avg_right_fit)\n",
    "#         avg_curverad = (left_curverad + right_curverad) / 2\n",
    "        \n",
    "#         cv2.putText(\n",
    "#             img=combined_img,\n",
    "#             text=\"Radius of Curvature = {curverad: d}(m)\".format(curverad=int(avg_curverad)),\n",
    "#             org=(50, 50),\n",
    "#             fontFace=cv2.FONT_HERSHEY_COMPLEX_SMALL,\n",
    "#             fontScale=2,\n",
    "#             color=(255,255,255),\n",
    "#             thickness=2,\n",
    "#             lineType=cv2.FILLED\n",
    "#         )\n",
    "        \n",
    "    # Draw distance from middle line.\n",
    "    y_point = 400  # Farther points tend to be slightly more stable than the ones near the camera, when dashed lines are present\n",
    "    left_fit_x = avg_left_fit[0] * y_point**2 + avg_left_fit[1] * y_point + avg_left_fit[2]\n",
    "    right_fit_x = avg_right_fit[0] * y_point**2 + avg_right_fit[1] * y_point + avg_right_fit[2]\n",
    "    \n",
    "    cv2.circle(combined_img, (int(left_fit_x), y_point), 5, (0, 255, 0), -1)\n",
    "    cv2.circle(combined_img, (int(right_fit_x), y_point), 5, (0, 255, 0), -1)\n",
    "    \n",
    "#     left_fit_x = scaled_avg_left_fit[0] * y_point**2 + scaled_avg_left_fit[1] * y_point + scaled_avg_left_fit[2]\n",
    "#     right_fit_x = scaled_avg_right_fit[0] * y_point**2 + scaled_avg_right_fit[1] * y_point + scaled_avg_right_fit[2]\n",
    "\n",
    "    mid = right_fit_x - left_fit_x\n",
    "    car_offset = (np.shape(combined_img)[1] / 2 - mid)\n",
    "    car_offset_text = \"Vehicle is {car_offset: .2f}px {direction_word} of center\"\n",
    "    \n",
    "    cv2.putText(\n",
    "        img=combined_img,\n",
    "        text=car_offset_text.format(\n",
    "            car_offset=np.absolute(car_offset),\n",
    "            direction_word=\"left\" if car_offset < 0 else \"right\"),\n",
    "        org=(50, 100),\n",
    "        fontFace=cv2.FONT_HERSHEY_COMPLEX_SMALL,\n",
    "        fontScale=2,\n",
    "        color=(255,255,255),\n",
    "        thickness=2,\n",
    "        lineType=cv2.FILLED\n",
    "    )\n",
    "    \n",
    "    return combined_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-11T19:05:05.493213Z",
     "start_time": "2018-09-11T19:04:35.170270Z"
    },
    "tags": [
     "#run-on-videos",
     "=>prev-work",
     "=>process",
     "=>path",
     "=>polylines-many"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video D:\\Linas\\projects\\CarND-Advanced-Lane-Lines\\results\\project_video.mp4\n",
      "[MoviePy] Writing video D:\\Linas\\projects\\CarND-Advanced-Lane-Lines\\results\\project_video.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▊| 75/76 [00:29<00:00,  2.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: D:\\Linas\\projects\\CarND-Advanced-Lane-Lines\\results\\project_video.mp4 \n",
      "\n",
      "Wall time: 29.7 s\n"
     ]
    }
   ],
   "source": [
    "video_in_folder  = os.path.join(root_folder, \"data\")\n",
    "video_out_folder = os.path.join(root_folder, \"results\")\n",
    "video_in_pattern = os.path.join(video_in_folder, \"*.mp4\")\n",
    "video_in_fnames  = glob.glob(video_in_pattern)\n",
    "video_out_fnames = [os.path.join(video_out_folder, os.path.basename(fname)) for fname in video_in_fnames]\n",
    "\n",
    "only_use_videos = [2]  # Only use videos with indices specified here\n",
    "use_subclip = True  # For testing\n",
    "\n",
    "for i in range(len(video_in_fnames)):\n",
    "    if only_use_videos and i not in only_use_videos:\n",
    "        continue\n",
    "    video_in_fname  = video_in_fnames[i]\n",
    "    video_out_fname = video_out_fnames[i]\n",
    "    \n",
    "    clip = VideoFileClip(video_in_fname)\n",
    "    if use_subclip:\n",
    "        clip = clip.subclip(0, 3)\n",
    "        \n",
    "    LINE_HISTORY_LENGTH = 7\n",
    "    left_lines = []\n",
    "    right_lines = []\n",
    "    prev_left_holder = [None]\n",
    "    prev_right_holder = [None]\n",
    "    scaled_left_lines = []\n",
    "    scaled_right_lines = []\n",
    "    \n",
    "    processed_clip = clip.fl_image(\n",
    "        lambda x: process_img(x,\n",
    "                              left_lines, right_lines, LINE_HISTORY_LENGTH,\n",
    "                              prev_left_holder, prev_right_holder,\n",
    "                              scaled_left_lines, scaled_right_lines\n",
    "        )\n",
    "    )\n",
    "\n",
    "    %time processed_clip.write_videofile(video_out_fname, audio=False)\n",
    "    \n",
    "    clip.close()\n",
    "    processed_clip.close()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-29T19:54:19.926053Z",
     "start_time": "2018-08-29T19:54:09.391567Z"
    },
    "tags": [
     "=>path",
     "=>init",
     "#combination"
    ]
   },
   "outputs": [],
   "source": [
    "# Display the videos\n",
    "video_in_folder  = os.path.join(root_folder, \"data\")\n",
    "video_out_folder = os.path.join(root_folder, \"results\")\n",
    "video_in_pattern = os.path.join(video_in_folder, \"*.mp4\")\n",
    "video_in_fnames  = glob.glob(video_in_pattern)\n",
    "video_out_fnames = [os.path.join(video_out_folder, os.path.basename(fname)) for fname in video_in_fnames]\n",
    "\n",
    "video_index = 0\n",
    "use_subclip = False\n",
    "\n",
    "composed_out_folder = os.path.join(root_folder, \"results\", \"intermediate\")\n",
    "composed_out_fname = os.path.join(composed_out_folder, \"yellow_detection_\" + os.path.basename(video_out_fnames[video_index]))\n",
    "\n",
    "original_clip = VideoFileClip(video_in_fnames[video_index]).resize(0.5)\n",
    "modified_clip = VideoFileClip(video_out_fnames[video_index]).resize(0.5)\n",
    "if use_subclip:\n",
    "    original_clip = original_clip.subclip(0, 10)\n",
    "    modified_clip = modified_clip.subclip(0, 10)\n",
    "composed_clip = clips_array([[original_clip, modified_clip]])\n",
    "\n",
    "composed_clip.write_videofile(composed_out_fname, audio=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-19T09:44:53.591586Z",
     "start_time": "2018-08-19T09:44:53.575631Z"
    }
   },
   "outputs": [],
   "source": [
    "original_clip.close()\n",
    "modified_clip.close()\n",
    "composed_clip.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxiliary Tools\n",
    "This should probably be split into a separate notebook, but I need some small tools to tinker with. E.g. I need to save one frame of an image to analyze the hue and lightness value of yellow line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-19T15:02:49.613927Z",
     "start_time": "2018-08-19T15:02:25.805976Z"
    },
    "tags": [
     "#aux-tools",
     "=>prev-work",
     "=>heuristics",
     "=>path"
    ]
   },
   "outputs": [],
   "source": [
    "# video_in_name  = os.path.join(root_folder, \"results\", \"project_video.mp4\")\n",
    "# video_in_name  = os.path.join(root_folder, \"results\", \"harder_challenge_video.mp4\")\n",
    "video_in_name  = os.path.join(root_folder, \"results\", \"intermediate\", \"channels\", \"s challenge_video.mp4\")\n",
    "out_folder = os.path.join(root_folder, \"results\", \"intermediate\", \"dissected\")\n",
    "\n",
    "clip = VideoFileClip(video_in_name)\n",
    "\n",
    "for i in range(int(clip.duration)):\n",
    "    out_filename = os.path.join(out_folder, \"frame_%d.png\" % i)\n",
    "    clip.save_frame(out_filename, t=i)\n",
    "    \n",
    "print(\"Done! Frames produced: %d\" % clip.duration)\n",
    "clip.close()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
